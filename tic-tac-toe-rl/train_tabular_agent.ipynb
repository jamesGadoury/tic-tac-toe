{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39110590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Self\n",
    "from functools import cache\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from time import time_ns\n",
    "from itertools import cycle\n",
    "from tic_tac_toe_board import TicTacToeBoard\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9901773",
   "metadata": {},
   "outputs": [],
   "source": [
    "WON_VALUE, DID_NOT_WIN_VALUE, DEFAULT_VALUE = 1.0, 0.0, 0.5\n",
    "\n",
    "@cache\n",
    "def serialize_board(board: TicTacToeBoard) -> str:\n",
    "    return \"\".join([str(c) for c in board.state])\n",
    "\n",
    "\n",
    "def populate_value_if_non_existent(value_table: dict, board: TicTacToeBoard):\n",
    "    key = serialize_board(board)\n",
    "    if key not in value_table:\n",
    "        value_table[key] = DEFAULT_VALUE\n",
    "    if board.first_player_won():\n",
    "        value_table[key] = WON_VALUE\n",
    "    elif board.second_player_won():\n",
    "        value_table[key] = WON_VALUE \n",
    "    elif board.tied():\n",
    "        value_table[key] = DID_NOT_WIN_VALUE\n",
    "\n",
    "def get_value(value_table: dict, board: TicTacToeBoard):\n",
    "    populate_value_if_non_existent(value_table, board)\n",
    "    return value_table[serialize_board(board)]\n",
    "\n",
    "def sample_value_table_policy(value_table: dict, board: TicTacToeBoard, eps: float = 0.0) -> tuple[float, bool]:\n",
    "    \"\"\"Returns action sampled from policy and bool indicating whether or not a greedy move was selected\"\"\"\n",
    "    populate_value_if_non_existent(value_table=value_table, board=board)\n",
    "    possible_plays: list[tuple[int, float]] = []\n",
    "    for idx in board.available_cell_indices():\n",
    "        next_board = board.transition(idx)\n",
    "        populate_value_if_non_existent(value_table=value_table, board=next_board)\n",
    "        possible_plays.append((idx, get_value(value_table, next_board)))\n",
    "\n",
    "    greedy_idx, _ = max(possible_plays, key=lambda t: t[1])\n",
    "    if len(possible_plays) > 1 and np.random.rand() < eps:\n",
    "        return np.random.choice([idx for idx, _ in possible_plays if idx != greedy_idx]), False\n",
    "\n",
    "    return greedy_idx, True\n",
    "\n",
    "def update_value(value_table: dict, last_board: TicTacToeBoard, current_board: TicTacToeBoard, learning_rate: float):\n",
    "    key_last = serialize_board(last_board)\n",
    "    # these two calls will auto‐create missing entries \n",
    "    v_last = get_value(value_table, last_board)\n",
    "    v_curr = (\n",
    "        get_value(value_table, current_board)\n",
    "        if current_board.player_to_move() == last_board.player_to_move()\n",
    "        else DID_NOT_WIN_VALUE # this is a terminal state backup, the last state did not lead to a winning terminal state\n",
    "    )\n",
    "    value_table[key_last] = v_last + learning_rate * (v_curr - v_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1bb5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(value_table, path):\n",
    "    print(f\"Saving to {path}\")\n",
    "    # dump keys as strings for JSON\n",
    "    export = {\"\".join(str(x) for x in k): v for k, v in value_table.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(export, f)\n",
    "\n",
    "def load(path):\n",
    "    raw = json.load(open(path, \"r\"))\n",
    "    return {tuple(int(c) for c in k): v for k, v in raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8ed6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: self play loop, agent plays both first and second player, changing its\n",
    "#       role after each turn\n",
    "\n",
    "FIRST_PLAYER_WON=\"first player won\"\n",
    "SECOND_PLAYER_WON=\"second player won\"\n",
    "TIE=\"tie\"\n",
    "\n",
    "# TODO: this is so gross lol make it not gross pls \n",
    "# TODO: replace debug with using logs instead of prints so we can set log level at top of notebook\n",
    "def train(value_table, n_episodes: int, learning_rate: float, epsilon: float, debug=False) -> dict:\n",
    "    outcomes = {FIRST_PLAYER_WON: 0, SECOND_PLAYER_WON: 0, TIE: 0}\n",
    "    for i in tqdm(range(n_episodes)):\n",
    "        current = TicTacToeBoard()\n",
    "        player_cycle = cycle([TicTacToeBoard.FIRST_PLAYER_CELL, TicTacToeBoard.SECOND_PLAYER_CELL])\n",
    "        last_greedy_state = None\n",
    "\n",
    "\n",
    "        while True:\n",
    "            player = next(player_cycle)\n",
    "            action, greedy = sample_value_table_policy(value_table=value_table, board=current, eps=epsilon)\n",
    "            last = current\n",
    "            current = current.transition(action)\n",
    "            if greedy:\n",
    "                update_value(value_table=value_table, last_board=last, current_board=current, learning_rate=learning_rate)\n",
    "            if current.terminated():\n",
    "                break\n",
    "            if greedy:\n",
    "                # NOTE: we do it after termination so that the player who went before this iter\n",
    "                #       has last_greedy_state set to their state, not updated to this\n",
    "                #       state (which already one)\n",
    "                last_greedy_state = current\n",
    "\n",
    "        if last_greedy_state is not None:\n",
    "            # backup other player's last greedy state to incorporate the loss or tie signal\n",
    "            update_value(value_table=value_table, last_board=last, current_board=current, learning_rate=learning_rate)\n",
    "\n",
    "        assert current.terminated(), \"should be terminated at end of episode\"\n",
    "        outcomes[FIRST_PLAYER_WON if current.first_player_won() else SECOND_PLAYER_WON if current.second_player_won() else TIE] += 1\n",
    "\n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbf2edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [06:03<00:00, 2747.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'first player won': 749998, 'second player won': 183419, 'tie': 66583}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "value_table = {}\n",
    "train(value_table=value_table, n_episodes=1000000, learning_rate=0.05, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356f9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_eval_policy(board: TicTacToeBoard) -> int:\n",
    "    player_to_move = board.player_to_move()\n",
    "    avail = board.available_cell_indices()\n",
    "    if len(avail) == 0:\n",
    "        raise ValueError(\"No moves left\")\n",
    "    for c in avail:\n",
    "        if board.transition(c).player_won(player_to_move):\n",
    "            return c\n",
    "    return int(np.random.choice(avail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27bdbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_policy(value_table, n_episodes, player):\n",
    "    outcomes = {FIRST_PLAYER_WON: 0, SECOND_PLAYER_WON: 0, TIE: 0}\n",
    "    # TODO: same as above training loop, make loop cleaner using cycle to switch through current player or somethign\n",
    "    for i in tqdm(range(n_episodes)):\n",
    "        current = TicTacToeBoard()\n",
    "\n",
    "        while True:\n",
    "            action = None\n",
    "            if player == TicTacToeBoard.FIRST_PLAYER_CELL:\n",
    "                action, _ = sample_value_table_policy(value_table=value_table, board=current, eps=0.0)\n",
    "            else:\n",
    "                action = sample_eval_policy(board=current)\n",
    "            current = current.transition(action)\n",
    "\n",
    "            # TODO: change to use logging\n",
    "            # current.display()\n",
    "\n",
    "            if current.terminated():\n",
    "                break\n",
    "\n",
    "\n",
    "            if player == TicTacToeBoard.SECOND_PLAYER_CELL:\n",
    "                action, _ = sample_value_table_policy(value_table=value_table, board=current, eps=0.0)\n",
    "            else:\n",
    "                action = sample_eval_policy(board=current)\n",
    "            current.transition(action)\n",
    "            # TODO: change to use logging\n",
    "            # current.display()\n",
    "            if current.terminated():\n",
    "                break\n",
    "        \n",
    "        assert current.terminated(), \"should be terminated at end of episode\"\n",
    "        outcomes[FIRST_PLAYER_WON if current.first_player_won() else SECOND_PLAYER_WON if current.second_player_won() else TIE] += 1\n",
    "\n",
    "    return outcomes\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8417eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3619.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'first player won': 10000, 'second player won': 0, 'tie': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_policy(value_table=value_table, n_episodes=10000, player=TicTacToeBoard.FIRST_PLAYER_CELL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3983bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to table<built-in function time_ns>.json\n"
     ]
    }
   ],
   "source": [
    "save(value_table=value_table, path=f\"table{time_ns}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeefe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how we serialize the table here breaks how the web app expects it\n",
    "\n",
    "# def serialize_to_ui_format(value_table):\n",
    "#     return {\"\".join([\"1\" if c == AGENT_CELL else \"2\" if c == OPPONENT_CELL else \"0\" for c in s]): v for s, v in value_table.items()}\n",
    "# save(value_table=serialize_to_ui_format(value_table=value_table), path=f\"ui_value_table{time_ns}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302e54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
